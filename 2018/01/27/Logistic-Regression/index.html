<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Deep Learning," />










<meta name="description" content="1:简介 我们知道其实 “深度学习” 是深层神经网络的重新包装，得益于GPU和大规模数据集的出现以及近几年算法的创新，神经网络重新焕发了生机。logistic regression 分类器可以看成一个单层的神经网络，若干个logistic regression单元有规律的组合就能形成可以处理复杂任务的深层神经网络，因此探讨logistic regression 的运行机制对于我们理解深层神经网络">
<meta name="keywords" content="Deep Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Logistic Regression">
<meta property="og:url" content="http://yoursite.com/2018/01/27/Logistic-Regression/index.html">
<meta property="og:site_name" content="Polaris">
<meta property="og:description" content="1:简介 我们知道其实 “深度学习” 是深层神经网络的重新包装，得益于GPU和大规模数据集的出现以及近几年算法的创新，神经网络重新焕发了生机。logistic regression 分类器可以看成一个单层的神经网络，若干个logistic regression单元有规律的组合就能形成可以处理复杂任务的深层神经网络，因此探讨logistic regression 的运行机制对于我们理解深层神经网络">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/neuron.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/sigmoid.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/costquxian.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/daijiazhexian.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/ML1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/fl1.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/tank.png">
<meta property="og:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/GL32.png">
<meta property="og:updated_time" content="2018-01-27T13:33:25.490Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Logistic Regression">
<meta name="twitter:description" content="1:简介 我们知道其实 “深度学习” 是深层神经网络的重新包装，得益于GPU和大规模数据集的出现以及近几年算法的创新，神经网络重新焕发了生机。logistic regression 分类器可以看成一个单层的神经网络，若干个logistic regression单元有规律的组合就能形成可以处理复杂任务的深层神经网络，因此探讨logistic regression 的运行机制对于我们理解深层神经网络">
<meta name="twitter:image" content="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/neuron.png">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/2018/01/27/Logistic-Regression/"/>





  <title>Logistic Regression | Polaris</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Polaris</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">You are what you do,not what you say.</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/01/27/Logistic-Regression/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhen Song">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Polaris">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Logistic Regression</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-01-27T21:32:01+08:00">
                2018-01-27
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="1简介"><a class="markdownIt-Anchor" href="#1简介"></a> 1:简介</h1>
<p>我们知道其实 “深度学习” 是深层神经网络的重新包装，得益于GPU和大规模数据集的出现以及近几年算法的创新，神经网络重新焕发了生机。logistic regression 分类器可以看成一个单层的神经网络，若干个logistic regression单元有规律的组合就能形成可以处理复杂任务的深层神经网络，因此探讨logistic regression 的运行机制对于我们理解深层神经网络有很大的好处。</p>
<h1 id="2神经元模型"><a class="markdownIt-Anchor" href="#2神经元模型"></a> 2:神经元模型</h1>
<p>我们目前使用的都是&quot;M-P神经元模型&quot;，在这个模型中，神经元接收到来自n个其它神经元传递过来的输入信号，这些输入信号通过带权重的连接进行传递，神经元接收到的总输入值将与阈值进行比较，然后通过&quot;激活函数&quot;处理以产生神经元的输出。</p>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/neuron.png" alt="M-P神经元模型"></p>
<h1 id="3logistic-regression-原理"><a class="markdownIt-Anchor" href="#3logistic-regression-原理"></a> 3:Logistic Regression 原理#</h1>
<p>目前神经网络的运行主要分为2个方向:遍历样本进行前向传播产生预测值;计算成本进行反向传播更新参数值。下面我们将分别介绍它们的工作原理。</p>
<h2 id="31前向传播"><a class="markdownIt-Anchor" href="#31前向传播"></a> 3.1:前向传播</h2>
<p>为了方便我们以后讨论问题，我们先定义如下符号：<br>
x:表示一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mrow><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>维的输入数据,其维度为(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mrow><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>,1).<br>
y:表示输出结果,取值为0或1.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mrow><mo fence="true">(</mo><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mi>i</mi><mo fence="true">)</mo></mrow></mrow></msup><mo separator="true">,</mo><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mi>i</mi><mo fence="true">)</mo></mrow></mrow></msup><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\left( x^{\left( i\right) },y^{\left( i\right) }\right)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.2380099999999998em;vertical-align:-0.35001em;"></span><span class="base textstyle uncramped"><span class="minner textstyle uncramped"><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size1">(</span></span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathit">i</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathit">i</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="style-wrap reset-textstyle textstyle uncramped" style="top:0em;"><span class="delimsizing size1">)</span></span></span></span></span></span>:表示第i组数据，可能是训练数据也可能是测试数据.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>X</mi><mo>=</mo><mo>[</mo><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mn>1</mn><mo fence="true">)</mo></mrow></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mn>2</mn><mo fence="true">)</mo></mrow></mrow></msup><mo separator="true">,</mo><mo>…</mo><mo>…</mo><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mi>m</mi><mo fence="true">)</mo></mrow></mrow></msup><mo>]</mo></mrow><annotation encoding="application/x-tex">X=[x^{\left( 1\right) },x^{\left( 2\right) },\ldots \ldots .,x^{\left( m\right) }]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.138em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mrel">=</span><span class="mopen">[</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">2</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="minner">…</span><span class="minner">…</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathit">m</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mclose">]</span></span></span></span>:表示数据集的输入值，放在一个<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mrow><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>xm的矩阵中，其中m表示样本数目.<br>
<span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>Y</mi><mo>=</mo><mo>[</mo><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mn>1</mn><mo fence="true">)</mo></mrow></mrow></msup><mo separator="true">,</mo><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mn>2</mn><mo fence="true">)</mo></mrow></mrow></msup><mo separator="true">,</mo><mo>…</mo><mo>…</mo><mi mathvariant="normal">.</mi><mo separator="true">,</mo><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mi>m</mi><mo fence="true">)</mo></mrow></mrow></msup><mo>]</mo></mrow><annotation encoding="application/x-tex">Y=[y^{\left( 1\right) },y^{\left( 2\right) },\ldots \ldots .,y^{\left( m\right) }]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.138em;vertical-align:-0.25em;"></span><span class="base textstyle uncramped"><span class="mord mathit" style="margin-right:0.22222em;">Y</span><span class="mrel">=</span><span class="mopen">[</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">2</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mpunct">,</span><span class="minner">…</span><span class="minner">…</span><span class="mord mathrm">.</span><span class="mpunct">,</span><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathit">m</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span><span class="mclose">]</span></span></span></span>:表示数据集的输出值，维度为1xm.<br>
用一对(x,y)来表示一个单独的样本，其中x代表<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msub><mi>n</mi><mrow><mi>x</mi></mrow></msub></mrow><annotation encoding="application/x-tex">n_{x}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.43056em;"></span><span class="strut bottom" style="height:0.58056em;vertical-align:-0.15em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">n</span><span class="vlist"><span style="top:0.15em;margin-right:0.05em;margin-left:0em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle cramped"><span class="mord scriptstyle cramped"><span class="mord mathit">x</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span>维的特征向量，y表示标签(输出结果)只能为0或1,其中(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mn>1</mn><mo fence="true">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">x^{\left( 1\right) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mn>1</mn><mo fence="true">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">y^{\left( 1\right) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.0824399999999998em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">1</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span></span></span></span>)表示第一个样本的输入和输出,(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mn>2</mn><mo fence="true">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">x^{\left( 2\right) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">2</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mn>2</mn><mo fence="true">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">y^{\left( 2\right) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.0824399999999998em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathrm">2</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span></span></span></span>)表示第二个样本的输入和输出,(<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>x</mi><mrow><mrow><mo fence="true">(</mo><mi>m</mi><mo fence="true">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">x^{\left( m\right) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:0.8879999999999999em;vertical-align:0em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit">x</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathit">m</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span></span></span></span>,<span class="katex"><span class="katex-mathml"><math><semantics><mrow><msup><mi>y</mi><mrow><mrow><mo fence="true">(</mo><mi>m</mi><mo fence="true">)</mo></mrow></mrow></msup></mrow><annotation encoding="application/x-tex">y^{\left( m\right) }</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.8879999999999999em;"></span><span class="strut bottom" style="height:1.0824399999999998em;vertical-align:-0.19444em;"></span><span class="base textstyle uncramped"><span class="mord"><span class="mord mathit" style="margin-right:0.03588em;">y</span><span class="vlist"><span style="top:-0.363em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="minner scriptstyle uncramped"><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">(</span><span class="mord mathit">m</span><span class="style-wrap reset-scriptstyle scriptstyle uncramped" style="top:0em;">)</span></span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0.7em;">​</span></span>​</span></span></span></span></span></span>)表示第m个样本的输入和输出。</p>
Z=W^{T}X+b$$  $$\widehat {Y}=g(Z)

<p>前向传播主要分为线性运算和激活运算,g指的激活函数。我们常用的激活函数有:sigmoid,tanh,softmax,relu等等。在深层神经网络中我们一般采用relu+softmax或relu+tanh,关于它们的优缺点和应用场景可以参考:<a href="https://www.jianshu.com/p/22d9720dbf1a" target="_blank" rel="noopener">常用激活函数比较</a> 在本例中我们采用sigmoid作为激活函数。</p>
<h2 id="32成本函数cost-function"><a class="markdownIt-Anchor" href="#32成本函数cost-function"></a> 3.2:成本函数(cost function)##</h2>
L\left( \widehat {y},y\right)=-(y\log \left( \widehat {y}\right)+\left( 1-y\right) \log \left( 1-\widehat {y}\right))

J(w,b)=\dfrac {1}{m}\sum ^{i=m}_{i=1}L(\widehat {y}^{\left( i\right) },{y}^{\left( i\right) })=-\dfrac {1}{m}\sum ^{i=m}_{i=1}(y\log \left( \widehat {y}\right)+\left( 1-y\right) \log \left( 1-\widehat {y}\right))

<p>在对网络进行反向传播之前,我们首先需要多前向传播计算的输出值和样本的真实值(标签值)之间的误差计算损失。loss function(L) 是在单个训练样本上定义的，它衡量了神经网络在单个训练样本上的表现;cost function(J) 是在全体样本上定义的，它衡量的是神经网络在全体训练样本上的表现。</p>
<h2 id="33反向传播"><a class="markdownIt-Anchor" href="#33反向传播"></a> 3.3反向传播##</h2>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>Z</mi><mo>=</mo><mi>A</mi><mo>−</mo><mi>Y</mi></mrow><annotation encoding="application/x-tex">dZ=A-Y
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.07153em;">Z</span><span class="mrel">=</span><span class="mord mathit">A</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.22222em;">Y</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>w</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>m</mi></mrow></mfrac><mo>∗</mo><mi>X</mi><mo>∗</mo><mi>d</mi><msup><mi>Z</mi><mrow><mi>T</mi></mrow></msup></mrow><annotation encoding="application/x-tex">dw=\dfrac {1}{m}*X*dZ^{T}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathit">m</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mbin">∗</span><span class="mord mathit" style="margin-right:0.07847em;">X</span><span class="mbin">∗</span><span class="mord mathit">d</span><span class="mord"><span class="mord mathit" style="margin-right:0.07153em;">Z</span><span class="vlist"><span style="top:-0.413em;margin-right:0.05em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle scriptstyle uncramped"><span class="mord scriptstyle uncramped"><span class="mord mathit" style="margin-right:0.13889em;">T</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>d</mi><mi>b</mi><mo>=</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mi>m</mi></mrow></mfrac><mo>∗</mo><mi>n</mi><mi>p</mi><mi mathvariant="normal">.</mi><mi>s</mi><mi>u</mi><mi>m</mi><mo>(</mo><mi>d</mi><mi>Z</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">db=\dfrac {1}{m}*np.sum(dZ)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:1.32144em;"></span><span class="strut bottom" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">d</span><span class="mord mathit">b</span><span class="mrel">=</span><span class="mord reset-textstyle displaystyle textstyle uncramped"><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span><span class="mfrac"><span class="vlist"><span style="top:0.686em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle cramped"><span class="mord textstyle cramped"><span class="mord mathit">m</span></span></span></span><span style="top:-0.22999999999999998em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped frac-line"></span></span><span style="top:-0.677em;"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span><span class="reset-textstyle textstyle uncramped"><span class="mord textstyle uncramped"><span class="mord mathrm">1</span></span></span></span><span class="baseline-fix"><span class="fontsize-ensurer reset-size5 size5"><span style="font-size:0em;">​</span></span>​</span></span></span><span class="sizing reset-size5 size5 reset-textstyle textstyle uncramped nulldelimiter"></span></span><span class="mbin">∗</span><span class="mord mathit">n</span><span class="mord mathit">p</span><span class="mord mathrm">.</span><span class="mord mathit">s</span><span class="mord mathit">u</span><span class="mord mathit">m</span><span class="mopen">(</span><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.07153em;">Z</span><span class="mclose">)</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>w</mi><mo>=</mo><mi>w</mi><mo>−</mo><mi>α</mi><mo>∗</mo><mi>d</mi><mi>w</mi></mrow><annotation encoding="application/x-tex">w=w-\alpha*dw
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mrel">=</span><span class="mord mathit" style="margin-right:0.02691em;">w</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mbin">∗</span><span class="mord mathit">d</span><span class="mord mathit" style="margin-right:0.02691em;">w</span></span></span></span></span></p>
<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math><semantics><mrow><mi>b</mi><mo>=</mo><mi>b</mi><mo>−</mo><mi>α</mi><mo>∗</mo><mi>d</mi><mi>b</mi></mrow><annotation encoding="application/x-tex">b=b-\alpha*db
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="strut" style="height:0.69444em;"></span><span class="strut bottom" style="height:0.77777em;vertical-align:-0.08333em;"></span><span class="base displaystyle textstyle uncramped"><span class="mord mathit">b</span><span class="mrel">=</span><span class="mord mathit">b</span><span class="mbin">−</span><span class="mord mathit" style="margin-right:0.0037em;">α</span><span class="mbin">∗</span><span class="mord mathit">d</span><span class="mord mathit">b</span></span></span></span></span></p>
<p>反向传播是神经网络进行训练和优化的重要环节，在训练集上利用优化算法最小化成本函数J(w,b)来得出最优的参数w,b。常见的优化算法有GD,SGD,RMSprop,ADAM,Adadelta等等。<a href="https://www.aiboy.pub/2017/09/10/A_Brief_Of_Optimization_Algorithms/" target="_blank" rel="noopener">优化算法的比较及代码实现</a>,接着我们就可以进行n次梯度循环，一步步达到最优值。下面我们将以吴恩达教授的猫脸识别为例详解 Logistic Regression 的代码实现。</p>
<h1 id="4代码实现"><a class="markdownIt-Anchor" href="#4代码实现"></a> 4:代码实现#</h1>
<h2 id="11sigmoid激活函数"><a class="markdownIt-Anchor" href="#11sigmoid激活函数"></a> 1.1:sigmoid激活函数##</h2>
<p>sigmoid用于神经网络的输出层，它可以将一个实数映射到(0，1)的区间，可以用来做二分类。<br>
<img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/sigmoid.png" alt="sigmoid"></p>
<h2 id="12激活函数代码实现"><a class="markdownIt-Anchor" href="#12激活函数代码实现"></a> 1.2:激活函数代码实现##</h2>
<pre><code>#定义激活函数
def activation_function(z):
    &quot;&quot;&quot;
    z --numpy array of any shape
    return:
    a --output of sigmoid(z),same shape as z
    &quot;&quot;&quot;
    a=(1.0/(1+np.exp(-z)))
    return a
</code></pre>
<h2 id="21参数初始化"><a class="markdownIt-Anchor" href="#21参数初始化"></a> 2.1:参数初始化##</h2>
<p>当你训练神经网络的时候，随机初始化权重（W）非常重要。对于有多个隐藏单元的神经网络，如果将权重参数全部初始化为0，再进行梯度下降是完全无效的，因为所有的隐藏单元都是对称的，不管你运行多长时间的梯度下降，它们都是在计算完全一样的函数，因此在多层神经网络中，不能将权重初始化为0，由于logistic regression只有一个隐藏单元，可以将权重初始化为0。对于偏置b 我们可以统一初始化为0。</p>
<h2 id="22参数初始化代码实现"><a class="markdownIt-Anchor" href="#22参数初始化代码实现"></a> 2.2:参数初始化代码实现##</h2>
<pre><code>#初始化参数 W，b=0 (如果有多个隐藏单元的时候,不能把w初始化为全0)
def initialize_parameters(dimension):
    &quot;&quot;&quot;
    W --weight matrix of shape (dimension,1)
    &quot;&quot;&quot;
    w=np.zeros((dimension,1))
    b=0
    return w,b
</code></pre>
<h2 id="31梯度循环"><a class="markdownIt-Anchor" href="#31梯度循环"></a> 3.1:梯度循环##</h2>
<p>梯度循环分为2部分：首先进行前向传播计算成本值；进行反向传播计算梯度值更新参数。</p>
<h2 id="32梯度循环代码实现"><a class="markdownIt-Anchor" href="#32梯度循环代码实现"></a> 3.2:梯度循环代码实现##</h2>
<pre><code>#定义梯度循环函数（包括 FP和BP）
#进行一次梯度循环后（遍历所有样本）返回得到的成本值和梯度值
def gradient_loop(w,b,X,Y):
    &quot;&quot;&quot;
    X:input of logistic regression e.g:cat photoes
    Y:label value of train_dataset
    return:
    cost of per gradient loop；dw,db from back propagation
    &quot;&quot;&quot;
    m=X.shape[1]
    A=activation_function(np.dot(w.T,X)+b)
    cost=-1.0/m*(np.sum(Y*np.log(A)+(1-Y)*np.log(1-A)))     
    dw=1.0/m*np.dot(X,(A-Y).T)
    db=1.0/m*np.sum(A-Y)
    gradients={&quot;dw&quot;:dw,
                &quot;db&quot;:db}
    return cost,gradients 
</code></pre>
<h2 id="41训练优化"><a class="markdownIt-Anchor" href="#41训练优化"></a> 4.1:训练优化##</h2>
<p>我们可以自己尝试设置学习率，梯度循环次数。进行多次训练求得最优的w，b 并且缓存w,b 作为预测模型的最终参数，预测其它的照片。</p>
<h2 id="42代码实现"><a class="markdownIt-Anchor" href="#42代码实现"></a> 4.2代码实现##</h2>
<pre><code>#经过n次梯度循环后,得到最终的w，b 更新参数，找出最优解而且也得到了n次循环的cost
def optimize(w,b,X,Y,number_gradient,learning_rate):
    &quot;&quot;&quot;
    costs[] --record cost of per gradient loop
    number_gradient --number of iterations of the gradient loop
    learning_rate --step value of the gradient descent update rule 
    returns:
    parameters --a dictionary containing w and b
    costs --a list containging cost
    &quot;&quot;&quot;
    costs=[]
    for i in range(number_gradient):
        cost,gradients=gradient_loop(w,b,X,Y)#每一次梯度循环遍历所有样本
        dw=gradients[&quot;dw&quot;]
        db=gradients[&quot;db&quot;]
        w-=learning_rate*dw
        b-=learning_rate*db
        if i%100==0:
            costs.append(cost)#每隔100次训练记录一次成本值
            print(&quot;梯度下降{0}后成本为:{1}&quot;.format(i,cost))
    parameters={&quot;w&quot;:w,
                &quot;b&quot;:b}
    return parameters,costs
</code></pre>
<h2 id="51产生预测模型"><a class="markdownIt-Anchor" href="#51产生预测模型"></a> 5.1:产生预测模型##</h2>
<p>经过多次的训练优化，我们就能得到使 cost function 最小的w,b(最优解)，下面我们就可以用从训练集上学到的最优的w,b 对测试集的照片进行预测。</p>
<h2 id="52代码实现"><a class="markdownIt-Anchor" href="#52代码实现"></a> 5.2:代码实现##</h2>
<pre><code>#对测试集进行预测，返回预测值矩阵
def prediction(w,b,X):
    m=X.shape[1]
    Y_prediction=np.zeros((1,m))
    Y_hat=activation_function(np.dot(w.T,X)+b)
    for i in range(m):
        if Y_hat[0][i]&gt;0.5:
            Y_prediction[0][i]=1
        else:
            Y_prediction[0][i]=0
    return Y_prediction
</code></pre>
<h2 id="61logistic-regression函数"><a class="markdownIt-Anchor" href="#61logistic-regression函数"></a> 6.1:Logistic Regression函数##</h2>
<p>我们已经实现了logistic regression 所需的所有子函数，现在我们就可以把它们组合起来形成完整的logistic regression 网络。</p>
<h2 id="62代码实现"><a class="markdownIt-Anchor" href="#62代码实现"></a> 6.2:代码实现##</h2>
<pre><code>def logistic_regression(X_train,Y_train,X_test,Y_test,number_gradient,learning_rate):
    w,b=initialize_parameters(X_train.shape[0])
    parameters,costs=optimize(w,b,X_train,Y_train,number_gradient,learning_rate)
    w=parameters[&quot;w&quot;]  #经过n次梯度循环后学习到的w
    b=parameters[&quot;b&quot;]  #经过n次梯度循环后学习到的b
    Y_prediction_train=prediction(w,b,X_train)
    Y_prediction_test=prediction(w,b,X_test)
    train_accuracy=100-np.mean(np.abs(Y_prediction_train-Y_train))*100
    test_accuracy=100-np.mean(np.abs(Y_prediction_test-Y_test))*100
    print(&quot;训练集识别准确度：{}%&quot;.format(train_accuracy))
    print(&quot;测试集识别准确度：{}%&quot;.format(test_accuracy))
    test_parameters={&quot;w&quot;:w,
                    &quot;b&quot;:b}
    return costs,test_parameters
</code></pre>
<h2 id="71测试"><a class="markdownIt-Anchor" href="#71测试"></a> 7.1:测试##</h2>
<p>我们可以随意设置学习率和梯度下降循环次数，观察神经网络的运行结果，为了方便查看可以使用matplotlib 库绘制cost 曲线。我设置了3个不同的学习率分别为0.018,0.012,0.006，循环次数为2000次，最后用三张照片测试算法的性能。</p>
<h2 id="72代码实现"><a class="markdownIt-Anchor" href="#72代码实现"></a> 7.2:代码实现##</h2>
<pre><code>learning_rate=[0.018,0.012,0.006]
for i in range(3):
    costs,test_parameters=logistic_regression(train_set_x,train_set_y_orig,test_set_x,test_set_y_orig,
                                          number_gradient=2000,learning_rate=learning_rate[i])
    #绘制代价函数曲线
    plt.plot(costs)
    plt.ylabel(&quot;cost&quot;)
    plt.xlabel(&quot;gradient loop&quot;)
    plt.title(&quot;learning rate=&quot;+str(learning_rate[i]))
    plt.show()
    if i==2:
        my_image = &quot;ML1.jpg&quot;    
        # We preprocess the image to fit your algorithm.
        fname = &quot;images/&quot; + my_image  #其中“images”是存储图像的文件夹
        image = ndimage.imread(fname, flatten=False)  #读取图片
        my_image = scipy.misc.imresize(image, size=(64,64)).reshape((1, 64*64*3)).T #放缩图像
        my_predicted_image = prediction(test_parameters[&quot;w&quot;], test_parameters[&quot;b&quot;], my_image)  #预测
        plt.imshow(image)
        print(&quot;y = &quot; + str(np.squeeze(my_predicted_image)) + &quot;, your algorithm predicts it is a \&quot;&quot; +
        classes[int(np.squeeze(my_predicted_image))].decode(&quot;utf-8&quot;) +  &quot;\&quot;picture.&quot;)    # \&quot;是python中双引号的转义字符  
</code></pre>
<h1 id="5运行结果"><a class="markdownIt-Anchor" href="#5运行结果"></a> 5运行结果#</h1>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/costquxian.png" alt="cost曲线"></p>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/daijiazhexian.png" alt="cost折线图"></p>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/ML1.png" alt="测试图1"></p>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/fl1.png" alt="测试图2"></p>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/tank.png" alt="测试图3"></p>
<p><img src="https://raw.githubusercontent.com/Polaris-SDU/test-result/master/GL32.png" alt="测试图4"></p>
<h1 id="6总结"><a class="markdownIt-Anchor" href="#6总结"></a> 6:总结#</h1>
<p>通过以上例程，我们明白了logistic regression 运行机制。我们观察到算法在测试集上的识别正确率约为68%，在训练集上识别正确率约为100%，即存在较大的偏差和方差。为了提高测试集识别正确率我们可以增加训练集的图片数目或者采用更深层的神经网络。我们以后会用4层的神经网络来识别猫脸，你会发现测试集的识别正确率能达到82%。<strong>完整的程序可以访问我的</strong><a href="https://github.com/Polaris-SDU/Polaris" target="_blank" rel="noopener">github</a></p>
<h1 id="7引用"><a class="markdownIt-Anchor" href="#7引用"></a> 7:引用#</h1>
<p>1:吴恩达教授 deep learning:<a href="http://study.163.com/my#/smarts" target="_blank" rel="noopener">http://study.163.com/my#/smarts</a><br>
2:周志华教授《机器学习》<br>
3:进击的加菲猫:<a href="https://www.aiboy.pub/2017/09/10/A_Brief_Of_Optimization_Algorithms/" target="_blank" rel="noopener">https://www.aiboy.pub/2017/09/10/A_Brief_Of_Optimization_Algorithms/</a><br>
4:不会停的蜗牛：<a href="https://www.jianshu.com/p/22d9720dbf1a" target="_blank" rel="noopener">https://www.jianshu.com/p/22d9720dbf1a</a></p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Deep-Learning/" rel="tag"># Deep Learning</a>
          
        </div>
      

      
      
      

      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Zhen Song</p>
              <p class="site-description motion-element" itemprop="description">An AI student</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">1</span>
                  <span class="site-state-item-name">标签</span>
                
              </div>
            

          </nav>

          

          

          
          

          
          
<br>
<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 
src="//music.163.com/outchain/player?type=2&id=4164331&auto=0&height=66"></iframe>
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#1简介"><span class="nav-number">1.</span> <span class="nav-text"> 1:简介</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2神经元模型"><span class="nav-number">2.</span> <span class="nav-text"> 2:神经元模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#3logistic-regression-原理"><span class="nav-number">3.</span> <span class="nav-text"> 3:Logistic Regression 原理#</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#31前向传播"><span class="nav-number">3.1.</span> <span class="nav-text"> 3.1:前向传播</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#32成本函数cost-function"><span class="nav-number">3.2.</span> <span class="nav-text"> 3.2:成本函数(cost function)##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#33反向传播"><span class="nav-number">3.3.</span> <span class="nav-text"> 3.3反向传播##</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4代码实现"><span class="nav-number">4.</span> <span class="nav-text"> 4:代码实现#</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#11sigmoid激活函数"><span class="nav-number">4.1.</span> <span class="nav-text"> 1.1:sigmoid激活函数##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#12激活函数代码实现"><span class="nav-number">4.2.</span> <span class="nav-text"> 1.2:激活函数代码实现##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#21参数初始化"><span class="nav-number">4.3.</span> <span class="nav-text"> 2.1:参数初始化##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#22参数初始化代码实现"><span class="nav-number">4.4.</span> <span class="nav-text"> 2.2:参数初始化代码实现##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#31梯度循环"><span class="nav-number">4.5.</span> <span class="nav-text"> 3.1:梯度循环##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#32梯度循环代码实现"><span class="nav-number">4.6.</span> <span class="nav-text"> 3.2:梯度循环代码实现##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#41训练优化"><span class="nav-number">4.7.</span> <span class="nav-text"> 4.1:训练优化##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#42代码实现"><span class="nav-number">4.8.</span> <span class="nav-text"> 4.2代码实现##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#51产生预测模型"><span class="nav-number">4.9.</span> <span class="nav-text"> 5.1:产生预测模型##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#52代码实现"><span class="nav-number">4.10.</span> <span class="nav-text"> 5.2:代码实现##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#61logistic-regression函数"><span class="nav-number">4.11.</span> <span class="nav-text"> 6.1:Logistic Regression函数##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#62代码实现"><span class="nav-number">4.12.</span> <span class="nav-text"> 6.2:代码实现##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#71测试"><span class="nav-number">4.13.</span> <span class="nav-text"> 7.1:测试##</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#72代码实现"><span class="nav-number">4.14.</span> <span class="nav-text"> 7.2:代码实现##</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#5运行结果"><span class="nav-number">5.</span> <span class="nav-text"> 5运行结果#</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#6总结"><span class="nav-number">6.</span> <span class="nav-text"> 6:总结#</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#7引用"><span class="nav-number">7.</span> <span class="nav-text"> 7:引用#</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhen Song</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({"tex2jax":{"inlineMath":[["$","$"],["\\(","\\)"]],"skipTags":["script","noscript","style","textarea","pre","code"],"processEscapes":true},"TeX":{"equationNumbers":{"autoNumber":"AMS"}}});
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
